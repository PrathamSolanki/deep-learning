{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"exercise_3_1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EqC4Tl0v_SXP","colab_type":"text"},"source":["\n","# Lab exercises 3\n","\n","For this lab exercises, please submit 2 notebooks / python script and 2 reports, one for each part. The deadline is 22 december.\n","\n","It is important the you read the documentation to understand how to use Pytorch functions, what kind of transformation they apply etc. You have to take time to read it carefully to understand what you are doing.\n","\n","    https://pytorch.org/docs/stable/nn.html\n","    https://pytorch.org/docs/stable/torch.html\n"]},{"cell_type":"markdown","metadata":{"id":"_jzQuRMr_oKt","colab_type":"text"},"source":["# 1. Part one: MNIST classification with Pytorch\n","\n","The goal of the first part is to learn how to use Pytorch and to observe the impact of regularization during training. You should test different network architectures, e.g. with hidden layers of size 128-128, 128-64-32-16, 256-128-64-32-16, 512-256-128-64-32-16, 800-800, and different activation functions (tanh, relu, sigmoid).\n","\n","Remember that Pytorch expects data in a different format than in the previous lab exercise: the first dimension is always the batch dimension."]},{"cell_type":"code","metadata":{"id":"h2vRn2VM_pWi","colab_type":"code","colab":{}},"source":["import os\n","import torch\n","import dataset_loader\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtisbNJDAG-t","colab_type":"code","outputId":"f085bd21-600c-402b-97cf-d44084275205","executionInfo":{"status":"ok","timestamp":1574952397157,"user_tz":-60,"elapsed":16098,"user":{"displayName":"Pratham Solanki","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlo2-DSwveVStpx6EtTeKypxgtNWdHD_nOwwms=s64","userId":"15166068430047448392"}},"colab":{"base_uri":"https://localhost:8080/","height":217}},"source":["# Download mnist dataset \n","if(\"mnist.pkl.gz\" not in os.listdir(\".\")):\n","    !wget http://deeplearning.net/data/mnist/mnist.pkl.gz\n","\n","# if you have it somewhere else, you can comment the lines above\n","# and overwrite the path below\n","mnist_path = \"./mnist.pkl.gz\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2019-11-28 14:46:24--  http://deeplearning.net/data/mnist/mnist.pkl.gz\n","Resolving deeplearning.net (deeplearning.net)... 132.204.26.28\n","Connecting to deeplearning.net (deeplearning.net)|132.204.26.28|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 16168813 (15M) [application/x-gzip]\n","Saving to: ‘mnist.pkl.gz’\n","\n","mnist.pkl.gz        100%[===================>]  15.42M  4.45MB/s    in 3.6s    \n","\n","2019-11-28 14:46:33 (4.25 MB/s) - ‘mnist.pkl.gz’ saved [16168813/16168813]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rw55v-6OAIFR","colab_type":"code","colab":{}},"source":["# load the 3 splits\n","train_data, dev_data, test_data = dataset_loader.load_mnist(mnist_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JpQ0AS26-nfW","colab_type":"code","outputId":"f449f1e7-e993-4c49-be5a-4ddb811ec5cc","executionInfo":{"status":"ok","timestamp":1574952397482,"user_tz":-60,"elapsed":7628,"user":{"displayName":"Pratham Solanki","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlo2-DSwveVStpx6EtTeKypxgtNWdHD_nOwwms=s64","userId":"15166068430047448392"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["image = torch.from_numpy(train_data[0][0])\n","print(image.shape) # flat image of dim (784,)\n","\n","# reshape the tensor so it is represented as a batch containing a single image\n","# -1 means \"all remaining elements\", here it would be equivalent to image.reshape(1, 784)\n","image = image.reshape(1, -1)\n","print(image.shape) # flat image of dim (1, 784)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["torch.Size([784])\n","torch.Size([1, 784])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gqhMWcWvikJJ","colab_type":"code","colab":{}},"source":["def create_batch(data, index, batch_size):\n","  if index + batch_size > len(data[0]): batch_size = len(data[0]) - index - 1\n","  return (torch.cat(\n","      [\n","          # we reshape the image tensor so it has dimension (1, 784)\n","          torch.from_numpy(image).reshape(1, -1)\n","          for image in data[0][index:index + batch_size]\n","      ],\n","      # we want to concatenate on the batch dimension\n","      dim=0),\n","\n","      torch.tensor(data[1][index:index + batch_size])\n","  )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"de497e92-0972-4db7-ace4-c7f3bb1f6bbf","executionInfo":{"status":"ok","timestamp":1574958909515,"user_tz":-60,"elapsed":1030,"user":{"displayName":"Pratham Solanki","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlo2-DSwveVStpx6EtTeKypxgtNWdHD_nOwwms=s64","userId":"15166068430047448392"}},"id":"uXFj58HNvvzE","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["create_batch(dev_data, 1230, 1)[1]"],"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([7])"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"markdown","metadata":{"id":"VAKydxtZAYJk","colab_type":"text"},"source":["## 1.2. Layer initialization\n","\n","By default, Pytorch will apply Kaiming initialization to linear layers. However, I recommend you to always explicitly initialize you network by hand in the constructor."]},{"cell_type":"code","metadata":{"id":"Ylf0BXm3oNaW","colab_type":"code","colab":{}},"source":["def get_activation(activations, index):\n","  if activations[index] == 'relu':\n","    return torch.relu\n","  elif activations[index] == 'leaky_relu':\n","    return torch.leaky_relu\n","  elif activations[index] == 'elu':\n","    return torch.elu\n","  elif activations[index] == 'tanh':\n","    return torch.tanh\n","  elif activations[index] == 'sigmoid':\n","    return torch.sigmoid\n","  else:\n","    raise Exception('unknown activation')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ku67jrvqqQpR","colab_type":"code","colab":{}},"source":["def get_initialization(activations, index):\n","  if activations[index] == 'relu':\n","    return torch.nn.init.kaiming_uniform_\n","  elif activations[index] == 'tanh':\n","    return torch.nn.init.xavier_uniform_\n","  else:\n","    return torch.nn.init.xavier_uniform_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"75DFOPAnjPOU","colab_type":"code","colab":{}},"source":["class Mlp_classifier(torch.nn.Module):\n","  def __init__(self, input_dim, num_classes, num_hidden_layers, hidden_layers_dim, activations, dropouts):\n","    assert isinstance(hidden_layers_dim, list)\n","    assert isinstance(activations, list)\n","    assert len(hidden_layers_dim) == num_hidden_layers\n","    assert isinstance(dropouts, list)\n","    assert len(dropouts) == num_hidden_layers + 1 # dropout is also for the input layer\n","\n","    self.activations = activations\n","    self.dropouts = [torch.nn.Dropout(p=d) for d in dropouts]\n","\n","    super().__init__()\n","\n","    self.z_projs = torch.nn.ModuleList()\n","\n","    i = 0\n","    previous_layer_dim = input_dim\n","    for hdim in hidden_layers_dim:\n","      linear = torch.nn.Linear(previous_layer_dim, hdim)\n","\n","      initialization = get_initialization(self.activations, i)\n","      initialization(linear.weight.data)\n","      torch.nn.init.zeros_(linear.bias.data)\n","      self.z_projs.append(linear)\n","      \n","      previous_layer_dim = hdim\n","      i += 1\n","\n","    self.output_proj = torch.nn.Linear(previous_layer_dim, num_classes)\n","\n","  def forward(self, batch):\n","    z = batch\n","    i = 0\n","    for nn in self.z_projs:\n","      z = self.dropouts[i](z)\n","      activation = get_activation(self.activations, i)\n","      z = activation(nn(z))\n","      i += 1\n","    out = self.output_proj(z)\n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I_zt86sWpibf","colab_type":"code","colab":{}},"source":["nn = Mlp_classifier(\n","    784,\n","    10,\n","    1,\n","    [100],\n","    ['relu'],\n","    [0,0.2]\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XoTnId8sXhC","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.SGD(\n","    nn.parameters(),\n","    lr=0.01\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8cwZT9ctzP7","colab_type":"code","colab":{}},"source":["loss_builder = torch.nn.NLLLoss(reduction='mean')\n","m = torch.nn.LogSoftmax(dim=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5lUghU4jsh5i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":199},"outputId":"8978a131-2d3d-4595-b46c-62300ea438e5","executionInfo":{"status":"ok","timestamp":1574962614644,"user_tz":-60,"elapsed":36362,"user":{"displayName":"Pratham Solanki","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlo2-DSwveVStpx6EtTeKypxgtNWdHD_nOwwms=s64","userId":"15166068430047448392"}}},"source":["batch_size = 64\n","n_epochs = 10\n","\n","for epoch in range(n_epochs):\n","  nn.train()\n","  for i in range(0,len(train_data[0]),batch_size):\n","    batch = create_batch(train_data, i, batch_size)\n","    x = batch[0]\n","    gold = batch[1]\n","    y = nn(x)\n","    loss = loss_builder(m(y),gold)\n","\n","    nn.zero_grad()\n","    loss.backward()\n","    torch.nn.utils.clip_grad_value_(nn.parameters(), 5.)  # clip gradient if its norm exceed 5\n","    optimizer.step()\n","\n","  nn.eval()\n","  dev_acc = 0\n","  for i in range(0,len(dev_data[0]),1):\n","    batch = create_batch(dev_data, i, 1)\n","    x = batch[0]\n","    gold = batch[1]\n","    y = nn(x)\n","\n","    if np.argmax(m(y).detach().numpy()) == gold: dev_acc += 1\n","\n","  dev_acc /= dev_data[0].shape[0]\n","  print(loss.data, dev_acc*100)"],"execution_count":133,"outputs":[{"output_type":"stream","text":["tensor(0.6878) 85.92999999999999\n","tensor(0.4179) 89.32\n","tensor(0.3148) 90.3\n","tensor(0.2614) 90.83\n","tensor(0.2281) 91.34\n","tensor(0.2061) 91.64999999999999\n","tensor(0.1914) 92.04\n","tensor(0.1801) 92.35\n","tensor(0.1711) 92.58999999999999\n","tensor(0.1637) 92.72\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8t0ALi1yw9Hx","colab_type":"code","colab":{}},"source":["def create_batch_conv(data, index, batch_size):\n","  if index + batch_size > len(data[0]): batch_size = len(data[0]) - index - 1\n","  return (torch.cat(\n","      [\n","          # we reshape the image tensor so it has dimension (1, 784)\n","          torch.from_numpy(image).reshape(1, 1, 28, 28)\n","          for image in data[0][index:index + batch_size]\n","      ],\n","      # we want to concatenate on the batch dimension\n","      dim=0),\n","\n","      torch.tensor(data[1][index:index + batch_size])\n","  )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-b9GxDKL-l20","colab_type":"code","colab":{}},"source":["class CNN_classifier(torch.nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.conv_model = torch.nn.Sequential(\n","        torch.nn.Conv2d(1,32,kernel_size=3),\n","        torch.nn.ReLU(),\n","        torch.nn.MaxPool2d(2,stride=2)\n","    )\n","\n","    self.linear = torch.nn.Linear(32*13*13,10)\n","\n","  def forward(self, batch):\n","    z = batch\n","    z = self.conv_model(z)\n","    z = z.view(-1, 32*13*13)\n","    return self.linear(z)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ROphbGf1Hs1F","colab_type":"code","colab":{}},"source":["cnn = CNN_classifier()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ki_dSWbZHzHF","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.SGD(\n","    cnn.parameters(),\n","    lr=0.01\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCJNVIRWH2HR","colab_type":"code","colab":{}},"source":["loss_builder = torch.nn.NLLLoss(reduction='mean')\n","m = torch.nn.LogSoftmax(dim=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Om3sq80RH7AW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":199},"outputId":"88b837ea-4f95-45de-df3e-610b5b240a1b","executionInfo":{"status":"ok","timestamp":1574963920763,"user_tz":-60,"elapsed":209659,"user":{"displayName":"Pratham Solanki","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlo2-DSwveVStpx6EtTeKypxgtNWdHD_nOwwms=s64","userId":"15166068430047448392"}}},"source":["batch_size = 64\n","n_epochs = 10\n","\n","for epoch in range(n_epochs):\n","  cnn.train()\n","  for i in range(0,len(train_data[0]),batch_size):\n","    batch = create_batch_conv(train_data, i, batch_size)\n","    x = batch[0]\n","    gold = batch[1]\n","    y = cnn(x)\n","    loss = loss_builder(m(y),gold)\n","\n","    cnn.zero_grad()\n","    loss.backward()\n","    torch.nn.utils.clip_grad_value_(cnn.parameters(), 5.)  # clip gradient if its norm exceed 5\n","    optimizer.step()\n","\n","  cnn.eval()\n","  dev_acc = 0\n","  for i in range(0,len(dev_data[0]),1):\n","    batch = create_batch_conv(dev_data, i, 1)\n","    x = batch[0]\n","    gold = batch[1]\n","    y = cnn(x)\n","\n","    if np.argmax(m(y).detach().numpy()) == gold: dev_acc += 1\n","\n","  dev_acc /= dev_data[0].shape[0]\n","  print(loss.data, dev_acc*100)"],"execution_count":152,"outputs":[{"output_type":"stream","text":["tensor(0.2950) 90.83\n","tensor(0.2283) 91.9\n","tensor(0.2001) 92.44\n","tensor(0.1805) 92.75\n","tensor(0.1640) 93.24\n","tensor(0.1495) 93.77\n","tensor(0.1361) 94.31\n","tensor(0.1240) 94.71000000000001\n","tensor(0.1130) 95.22\n","tensor(0.1031) 95.63000000000001\n"],"name":"stdout"}]}]}